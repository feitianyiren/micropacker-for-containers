# micropacker-for-containers

Kernel assisted microcontainerization PoC.

Micropacker-for-containers is a PoC that will help you micro-containerize a container in a potentially faster and more effective way than the more common "trial and error" [approach](https://hackernoon.com/how-to-build-a-tiny-httpd-container-ae622c37db39#c81d). If you are interested in learning first what a microcontainer is, have a look at a general introduction [here](https://blogs.oracle.com/developers/the-microcontainer-manifesto).

There is also the small chance that you are here because you already know what microcontainers are, but you don't want to use a "tiny" base image like the ones provided by Google in the [distroless](https://github.com/GoogleContainerTools/distroless) project but rather build your own.

This project follows a KISS approach, trying to do only a few things and heavily leveraging other open-source utilities to build the final microcontainer image.

## General overview

The basic steps:

1. Put your kernel in "listening" mode  

2. Run all your tests against your target container to trigger its functionalities  

3. Export the information captured by the kernel in a human-readable format with `sysdig` and `microdump.lua`  

4. Copy `micropacker.py` to a newly create target container and execute it, using the file generated at the above step in input.  
   As `micropacker.py` is written in Python 3, this implies that you need to modify your container runtime to install the Python 3 package and all the needed dependencies if you don't have them already in your image.

## Why micropacker-for-containers

The are basically three ways an executable can reference functions declared in a library:

* use static linking
* use dynamic linking
* use dynamic loading (look at `dlopen` [man page](https://linux.die.net/man/3/dlopen))

The first two ways don't really pose a problem for packaging microcontainers, everything is already in your executable with static linking and you can use the output of something like `ldd` to gather the list of the dynamically linked libraries. Dynamic loading instead is an issue, as you would need to disassemble your target binary and all its shared libraries to make sense of opcodes that might also be performing string manipulation before the `dlopen` call. Just as an example, see the [error](https://hackernoon.com/how-to-build-a-tiny-httpd-container-ae622c37db39#c81d) generated by a dynamically loaded `libuuid` library missing from a microcontainer.

The good news is that not only the glibc `dlopen` call, but also virtually every file opened by the target binary can be intercepted by listening to syscalls.

Since we have to dump this information from the kernel, instead of reinventing the wheel (or a system call table rootkit!), [sysdig](https://sysdig.com/opensource/) seems a good solution. You are not forced to use `sysdig` provided that you give `micropacker.py` a compatible file in input, you can even write the input file by hand. Micropacker-for-containers just makes your life easier providing a [chisel](https://github.com/draios/sysdig/wiki/Chisels-Overview) in the repo, which are small Lua scripts that allow you to extend `sysdig` functionality. The `microdump.lua` script is used to generate a human readable file that is exactly what `micropacker.py` expects.

## Getting Started

It's best to explain kernel-assisted micropacking by seeing it in action against a normal container.

For this README, I've picked the development version of project [Admiral](https://hub.docker.com/r/vmware/admiral/), an open-source Java application based on Photon 1.0 that you can download from Docker Hub by pulling `vmware/admiral:dev`.

### Prerequisites

#### On the host

On an Ubuntu/Debian system, satisfying prerequisites on the host shouldn't be different from:

```console
root@host:~# apt-get install sysdig
root@host:~# cp microdump.lua /usr/share/sysdig/chisel/
```

On a Photon OS system instead:

```console
root@host:~# tdnf install sysdig
root@host:~# cp microdump.lua /usr/share/sysdig/chisel/
```

#### On the container

In addition to the Python 3 runtime, you will later need to install the `python3-pyelftools` and, optionally, the `python3-rpm` and `python3-apt` dependencies.
Don't modify your image, but rather follow the following instructions in a container when needed. Also, don't worry too much about a `virtualenv`, we are going to throw away the modified container anyway at the end.

On an Ubuntu/Debian based container:

```console
root@container:~# apt-get update
root@container:~# apt-get install python3 python3-apt python3-pyelftools --no-install-recommends
```

In case python3-pyelftools is not packaged (i.e. Debian wheezy):

```console
root@container:~# apt-get update
root@container:~# apt-get install python3-pip ca-certificates --no-install-recommends
root@container:~# pip-3.2 install --index-url=https://pypi.python.org/simple/ pyelftools
```

On a Photon 2.0 based container:

```console
root@container:~# tdnf --refresh install python3 python3-rpm python3-pip python3-setuptools
root@container:~# pip3 install pyelftools
```

On a Photon 1.0 based container:

```console
root@container:~# tdnf --refresh install python3 python3-rpm
root@container:~# pip3 install pyelftools
```

### Put sysdig in listening mode on the host

Ask `sysdig` to perform a raw capture of everything that happens on your target container:

```console
root@host:~# sysdig -qw kdump.cap container.image=vmware/admiral:dev &
```

Pull your target image and start it normally:

```console
root@host:~# docker pull vmware/admiral:dev
root@host:~# docker run -d -p 8282:8282 vmware/admiral:dev
```

### Run __ALL__ the tests you have

This is the key part: __the approach is as good as your QA__.

The kernel will see as many `dlopen` calls (actually it sees `open` syscalls) as deep your functional testing is. Trigger every functionality/feature of the product, possibly with automated tests as part your CI/CD pipeline.

### Create a rootfs.tar archive from the container

Stop the `sysdig` capture and use `microdump.lua` to get your "needed files" list.

```console
root@host:~# kill <sysdig PID>
root@host:~# docker stop <cid>
root@host:~# sysdig -r kdump.cap -c microdump | sort | uniq > files.txt
```

Copy the `micropacker.py` and `files.txt`, then jump inside a __new__ Admiral container, overriding the `ENTRYPOINT` tag and running as root:

```console
root@host:~# docker run -dit --entrypoint=/bin/sh -u=0 vmware/admiral:dev
root@host:~# docker cp ./files.txt [cid]/tmp
root@host:~# docker cp ./micropacker.py [cid]/tmp
root@host:~# docker exec -it [cid] /bin/sh
```

Now install the Python dependencies as described before and then run the `micropacker.py` script, specifying at least the input list and a filename for the output tar archive:

```console
root@container:~# cd /tmp
root@container:~# python3 micropacker.py -i files.txt -t rootfs.tar
```

In case you want to collect information about which RPM/DEB package a file belongs to, run with the `--rpm` or `--deb` switch. For instance, as Photon OS is a RPM based distro:

```console
root@container:~# cd /tmp
root@container:~# python3 micropacker.py -i files.txt -t rootfs.tar --rpm > package_info.txt
```

Take some time to look at the `package_info.txt` file to understand if you can benefit in some way of this information in your release process.

### Build your micro image

Now that you have the `rootfs.tar` archive, a microcontainer is just a matter of creating an appropriate Dockerfile.  
Copy back the `rootfs.tar` file to your host and create a Dockerfile that contains the needed `ENV`, `VOLUME`, `WORKDIR`, `EXPOSE` tags as the original one... basically everything except the `FROM`, `RUN`, `COPY` and `ADD` tags. Do not forget Dockerfile tags that are set by parent Dockerfiles!

```dockerfile
FROM "scratch"
ENV JAVA_HOME=/usr/lib/jvm/default-jvm \
  ADMIRAL_PORT=8282 \
  ADMIRAL_STORAGE_PATH=/var/admiral/ \
  USER_RESOURCES=/etc/xenon/user-resources/system-images/ \
  ADMIRAL_ROOT=/admiral \
  MOCK_MODE=false
ENV DIST_CONFIG_FILE_PATH=$ADMIRAL_ROOT/config/dist_configuration.properties
ENV CONFIG_FILE_PATH=$ADMIRAL_ROOT/config/configuration.properties
ENV LOG_CONFIG_FILE_PATH=$ADMIRAL_ROOT/config/logging.properties
ENV HOME=$ADMIRAL_ROOT
ENV TERM=xterm

WORKDIR $ADMIRAL_ROOT
EXPOSE $ADMIRAL_PORT
VOLUME $ADMIRAL_STORAGE_PATH

ADD rootfs.tar /
ENTRYPOINT ["/entrypoint.sh"]
```
A quick way to get environment variables is also the `env` command once inside a container.
Now build the Dockerfile, start the micrcontainer and then try to `docker exec` to the microcontainerized Admiral!

## Advanced usage

Check the usage of `micropacker.py` for advanced options.

## Misc

The code was tested with a few versions of Python 3, the oldest being Python 3.2.3 on Debian Wheezy. It is unlikely that you will run it on any older Python 3 runtime, but feel free to open an issue if you encounter problems.

Release binaries are not currently being considered, as they require additional work from a legal/licensing standpoint.

## License

The project is licensed under the BSD 2-clause license, see the [LICENSE.txt](LICENSE.txt) file for the full text.